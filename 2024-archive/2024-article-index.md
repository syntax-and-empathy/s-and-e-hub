# AI Trials: 2024
January of 2024 marked the beginning of a series of experiments designed to test the capabilities of five AI models—Bard, Claude, Copilot, ChatGPT-4, and LLaMA—in creating content about New Year’s celebrations around the world. Each AI exhibited unique strengths and weaknesses, emphasizing the necessity of human oversight to ensure the accuracy and reliability of AI-generated content.

---

## January
In January I focused on evaluating the performance of AI models like ChatGPT, Bard, and Claude in generating content about global holiday traditions. Key experiments included generating articles on Martin Luther King Jr. Day and Makar Sankranti, revealing the importance of detailed prompts and human oversight in achieving high-quality content.

### AI Trials: January Pt 1
In the first part of January's AI trials, five AI models—Bard, Claude, Copilot, ChatGPT-4, and LLaMA—were tested to generate content about New Year's celebrations in the world's most populous countries. Bard produced the most detailed information but with accuracy issues, while Claude and Copilot underperformed. This trial underscored the necessity of human verification due to errors and inconsistent data. The AI models were tasked with creating event guides for January 2024, revealing their varying capabilities and limitations. Despite challenges, valuable insights were gained on the strengths and weaknesses of each AI in content creation.

### AI Trials: January Pt 2
Continuing from the first trial, January Part 2 expanded the scope to 16 countries, including Ukraine. The AI models were instructed to compile detailed tables of holidays and events. LLaMA faced frequent issues, while ChatGPT-4 required multiple sessions to stay on track. Bard provided detailed lists, albeit with inaccuracies, and Claude offered concise but minimal content. The integration of native language names added complexity. This phase highlighted the need for human oversight in verifying AI-generated data and the varied performance of different AI tools in managing extensive datasets. Key takeaways emphasized the critical role of human verification and the ongoing refinement of AI capabilities.

---

Next, I shifted focus to evaluating how well AI could generate content for specific holidays, such as Martin Luther King Jr. Day, Makar Sankranti, and the 1952 Egyptian Revolution. The experiments involved ChatGPT, Bard, and Claude, testing their abilities in increasingly specialized roles. Additionally, a framework for evaluating historical articles was developed using ChatGPT-4 and Claude.

### AI Trials: January Pt 3
In January Part 3, the focus shifted to evaluating AI-generated content on specific holidays using increasingly specialized roles. ChatGPT, Bard, and Claude were tasked with writing articles on Martin Luther King Jr. Day, Makar Sankranti, and the 1952 Egyptian Revolution. Each AI faced unique challenges: Bard initially resisted using templates, Claude struggled with length constraints, and ChatGPT performed consistently well. The tests revealed that detailed and precise prompting enhanced the quality of AI-generated content but highlighted the persistent need for human oversight. The experiment emphasized the importance of refining prompts and setting clear role expectations for optimal AI performance.

### AI Trials: January Pt 4
In January Part 4, developing a framework with ChatGPT and Claude for evaluating historical articles was the focus. This framework was then used to assess holiday-themed articles, revealing initial inconsistencies in AI evaluations. After refining the criteria, alignment improved, showcasing the importance of providing detailed context and examples. The evaluation of Martin Luther King Jr. articles underscored the balance between depth and breadth in content. Key takeaways included the necessity of human oversight, the value of collaborative criteria development, and the complexity of directing AI in nuanced tasks. This phase highlighted the iterative process required to refine AI-assisted content evaluation.

---

## February
In February, the series of AI experiments continued with a detailed focus on specialized roles and content generation. This month involved testing the capabilities of various AI models to create, critique, and improve articles on cultural events, specifically the Spring Festival in China.

### AI Trials: February Pt 1
In February Pt 1, I explored how specialized AI roles impact content creation, focusing on ChatGPT-4 and Claude v2.1. By tailoring roles for each AI, I sought to enhance output precision and relevance. ChatGPT-4 generated detailed, structured content with minimal prompts, excelling at systematic documentation. However, Claude v2.1 struggled, especially with role-playing deviating from the task. Through iterative feedback and adjustments, significant improvements were achieved, highlighting the crucial role of human oversight in ensuring AI-generated content is culturally sensitive and accurate.

### AI Trials: February Pt 2
In February Part 2, I focused on refining and applying a standardized rating system for AI-generated content. An Expert Editor evaluated the accuracy, relevance, and quality of articles created by ChatGPT-4 and Claude v2.1. The trials highlighted the importance of detailed criteria and the challenges in maintaining consistency. ChatGPT-4 excelled with minimal prompting, while Claude needed more specific guidance. Key insights emphasized the need for precise instructions and iterative feedback to enhance AI performance in content evaluation tasks.

### AI Trials: February Pt 3
In February Part 3, I used specialized AI roles to create detailed articles about the first day of the Spring Festival. ChatGPT-4 generated comprehensive content without additional prompts, while Claude v2.1 struggled, especially with image descriptions. This trial underscored the importance of clear role definitions—differentiating between "role-playing" and "assuming a role"—and providing precise instructions to optimize AI performance and ensure culturally sensitive content.

### AI Trials: February Pt 4
In February Part 4, the focus was on refining Claude's role in creating culturally sensitive content about China's Spring Festival. Initially lacking cultural sensitivity, Claude adapted to iterative feedback to produce a respectful and accurate article. This phase emphasized the need for clear instructions and human oversight to ensure AI-generated content is appropriate, reinforcing the collaborative nature of human-AI interactions.

---

Continuing with Spring Festival, Claude, ChatGPT, and Gemini were given a set of instructions to follow, highlighting the diversity in their outputs and the need for precise prompts. Key themes include the importance of historical context, cultural significance, and the challenges of maintaining consistency across different AI platforms.

### AI Trials: February Pt 5
In February Part 5, I worked on refining AI-generated content by leveraging specialized roles and structured prompts. Despite encountering challenges with image descriptions and editorial precision, the trials revealed the distinct strengths of each AI model. ChatGPT excelled in enriching content with historical insights, while Claude demonstrated a tendency towards concise output. These experiments showed the challenges and benefits of using AI in creative work, emphasizing the importance of continually adapting to best combine human skill and AI power.

### AI Trials: February Pt 6
In February Part 6, I refined methods for evaluating AI-generated content, focusing on writing tasks. ChatGPT and Gemini showed strong writing skills, but Gemini had trouble staying on topic. The trials showed that precise prompts are key to guiding AI responses. This phase highlighted the need for adaptable approaches and a balance of structured guidance and flexibility to improve AI content creation. The experiments demonstrated AI's potential in professional contexts, with ongoing refinement and human oversight.

### AI Trials: February Pt 7
In February Part 7, I explore how structured prompts affect AI-generated content. The tests showed that while structured prompts greatly improve content quality, they also make it harder to correct AI inaccuracies. ChatGPT and Claude wrote culturally informed articles, with ChatGPT standing out for its historical detail and engaging storytelling. Key insights revealed the balance between harnessing AI's strengths and managing its weaknesses.

### AI Trials: February Pt 8
In February Part 8, I combined specialized roles like an experienced writer, editor, and photographer with AI to enhance content creation. ChatGPT suggested adding an ethical lens to the review process, which was incorporated. The importance of clear instructions and human oversight to ensure AI-generated content meets project and ethical standards remained constant.

---

## March
March’s focus was on using AI tools like Midjourney and Stable Diffusion to generate visual content for cultural celebrations such as Holi. This experience emphasized the importance of precise prompt engineering and human oversight to create culturally sensitive and visually appealing content.

### AI Trials: March Pt 1
In March Part 1, I used AI tools like Midjourney, Leonardo.ai, and Stable Diffusion to generate Holi festival images and assess their handling of complex visual prompts. Midjourney v6 produced high-quality images with minimal issues, Leonardo.ai excelled in close-ups but struggled with larger scenes, and Stable Diffusion needed extensive negative prompts for acceptable results. The trials emphasized the importance of precise prompt engineering and revealed each AI model's strengths and weaknesses in creating culturally sensitive, visually appealing content.

### AI Trials: March Pt 2
In March Part 2, I further explored AI-generated Holi festival imagery using Leonardo.ai, Midjourney, and Stable Diffusion, emphasizing effective prompt engineering. Midjourney v6 provided high-quality images effortlessly, Leonardo.ai excelled in close-ups but struggled with larger scenes, and Stable Diffusion needed extensive negative prompts for acceptable results. The trials highlighted the importance of iterative refinement and human oversight to optimize AI-generated content for cultural and aesthetic accuracy.

---

## April
April involved establishing baselines and benchmarks for AI-generated content using updated tools. The experiments focused on refining roles and templates, revealing improvements in content quality and the necessity of combining AI capabilities with human expertise for optimal results.

### AI Trials: April Pt 1
In April Part 1, I established baselines and benchmarks for AI-generated content using the updated Minion Maker (RMv3). This included refining roles and evaluating the performance of Claude, ChatGPT-4, and Gemini Pro in creating articles for various holidays. Key findings showed improvements in role adaptation and content quality, with the experiments providing valuable insights into the capabilities and limitations of each AI model in generating culturally sensitive and accurate content.

### AI Trials: April Pt 2
In April Part 2, I continued to refine the AI-generated content by focusing on standardized templates and rating criteria. This phase involved creating articles for Eid al-Fitr using Claude, ChatGPT-4, and Gemini Pro. Next, I explored the use of structured prompts and XML integration, which significantly improved content quality. Despite challenges with word count and prompt specificity, the experiments highlighted the importance of combining AI capabilities with human expertise to achieve high-quality content.

### AI Trials: April Pt 2+
In April Part 2+, I focused on evaluating AI-generated articles through the enhanced roles and structured templates. The trials involved 21 articles written by Claude, ChatGPT-4, and Gemini Pro, with evaluations based on refined criteria. The experiments showed that using detailed prompts and integrating XML significantly improved content quality and adherence to templates. This run of articles further underscores the need for continuous refinement of prompts and roles to optimize AI-generated content.

---

## May
In May, I tested various tones in AI-generated content about Japan’s Golden Week. The experiments showed significant variability in content quality based on tone selection, highlighting the need for precise prompting and iterative refinement to optimize AI output.

### AI Trials: May Pt 1
In May Pt 1, I explored how various tones affect AI-generated content about Japan's Golden Week using Claude and ChatGPT. The results showed significant variability in content quality, engagement, and coherence, as well as instances where the template was entirely ignored. This trial highlighted the challenges in maintaining consistent evaluation criteria, the importance of refining prompts, and the need for clearer guidelines. It also demonstrated the nuanced impact of tone selection on the engagement of AI-generated content.

### AI Trials: May Pt 2
In May Pt 2, I tested how various tones impact AI-generated content quality for Golden Week. Using Claude and ChatGPT, I generated articles in simple, conversational, creative, descriptive, and professional tones and evaluated Constitution Day image descriptions. Certain tones boosted engagement and readability, while others caused inconsistencies. Claude excelled with professional and descriptive tones; ChatGPT was strong in conversational and simple tones. This further highlighted the importance of precise prompting and iterative refinement to optimize AI output.

### AI Trials: May Pt 3
In May Pt 3, I used GPT-4, GPT-4o, and GPT-3.5 to evaluate articles on Vesak and Memorial Day. The trials involved structured prompts and refined evaluation criteria to assess content quality. GPT-4 excelled at generating engaging and accurate content, while GPT-4o and GPT-3.5 showed mixed results, highlighting their respective strengths and limitations. This round underlined the necessity of clear instructions and consistent evaluation criteria, and demonstrated the importance of iterative feedback and continuous refinement in optimizing AI performance.

---

## June
In June, I assessed the ability of ChatGPT-4 and Claude to generate culturally themed content with consistent tones for events like the Dragon Boat Festival and Eid al-Adha. The AI showed diverse interpretations of tonal instructions in creating coherent and culturally appropriate content.

### AI Trials: June Pt 1
In June Pt 1, the focus was on exploring the AI's ability to select and utilize different tones autonomously while generating culturally themed articles. This phase involved testing ChatGPT-4 and Gemini on producing articles about the Dragon Boat Festival and Brazilian Valentine’s Day in five distinct tones: Informative/Explanatory, Engaging/Conversational, Descriptive/Creative, Professional/Formal, and Optimistic/Celebratory. The experiment revealed significant variations in how effectively the AIs could adapt their tone.

### AI Trials: June Pt 2
The experiments in June Pt 2 explored Claude's and ChatGPT-4's ability to maintain a consistent tone across articles about Eid al-Adha celebrations in Bangladesh and Egypt. These trials assessed each AI's ability to interpret instructions and produce culturally sensitive content with a coherent tone, revealing nuances in processing instructions as well as challenges like false starts and inconsistencies in article scoring.

### AI Trials: June Pt 3
June Pt 3 supplements the previous experiments by detailing the roles and templates used throughout the trials.

---

## Midpoint
I started a project six months ago to test AI platforms and understand their potential for everyday use. What began as a simple evaluation grew into a series of experiments. Now, at the halfway mark, I have learned more than I can share in a post. As such, this will have to serve as a summary, setting the stage for future in‐depth pieces.

> When I started, I was looking to expand my toolkit. Instead, I was reminded that creativity thrives when free, unchained by rigid processes and procedures. AI promised efficiency and productivity but gave me a challenge:
>
> **"Dig deeper – I'll hold your scotch."**

My approach evolved through exploring various prompting techniques. While "cheatsheets" and claims of "simple prompts" were clearly basic, they served as initial signposts, guiding me towards more substantive experiments with roles, templates, tones, and beyond.

Additionally, the past year has seen a number of releases, notably Anthropic's Claude iterations and OpenAI's GPT-4 updates. These advancements enhanced AI's ability to understand context and solve problems. As new models emerged, I expanded testing to include various model versions, adding another dimension to my experiments.

### Major AI Model Releases:
- **ChatGPT-3.5** (November 2022)
- **Bard** (March 2023)
- **ChatGPT-4** (March 2023)
- **Custom GPTs** (July 2023)
- **Claude 2.1** (November 2023)
- **ChatGPT-4 Turbo** (November 2023)
- **Gemini Pro 1.0** (December 2023)
- **Gemini Pro 1.5** (February 2024)
- **Claude 3 Sonnet** (March 2024)
- **ChatGPT-4o** (May 2024)
- **Claude 3.5 Sonnet** (June 2024)

With AI evolving so quickly, I focused on maintaining baselines for comparing improvements across model iterations. Areas of focus in this project include:
1. **Data Collection**: Creating simple event guides, which have evolved into comprehensive holiday tables that revealed inconsistencies across AI models and required meticulous cross-referencing.
2. **Specialized Roles**: Assigning roles, which progressed from general to highly specialized, task-specific roles, culminating in the development of a GPT for the purpose of creating them with little effort.
3. **Template Development**: Creating standardized templates for consistent article structure, allowing me to establish scoring mechanisms despite occasional AI deviations.
4. **Output Examples**: Using example articles to guide authoring and evaluation, which proved challenging when attempting to calibrate scoring spectrums independently.
5. **Evaluation Methods**: Developing a framework to assess quality, ethics, and cultural sensitivity, which continues to face challenges in achieving consistent success across multiple tests.
6. **Tone Consistency**: Exploring AI's ability to maintain consistent tones and styles across diverse content, revealing varied results and the depth added by prescribed tones.

---

## July
In July, I tested a new GPT for role creation and explored JSON as an alternative to Markdown. Trials across five holidays yielded mixed results, with the new GPT showing only marginal improvements. I also used Claude and ChatGPT-4o to create charts, significantly reducing data visualization time.

### AI Trials: July Pt 1
In July Pt 1, I began winding down role tests with a final push to validate recent findings after AI model updates. I compared a newer version of the role creation GPT with its predecessor, finding no significant improvements. Additionally, I experimented with JSON as an alternative to Markdown, which produced mixed results. These trials continued to refine our understanding of AI-assisted content creation techniques.

### AI Trials: July Pt 2
In July Pt 2, I tested AI roles across five holidays. Despite past improvements, results were underwhelming, with GPT-4 showing inconsistency and Claude performing better with JSON. Analysis of 60 score sets revealed diminishing returns in the current role-creation method. The project also explored data visualization, with GPT-4 experiencing issues on less common chart types.

---

## August
In August, I worked with different prompting styles to improve how the AI roles approached their varying tasks, the scoring criteria, and the template I had been developing.

### AI Trials: August Pt 1
To start the month, I utilized Claude 3.5 Sonnet and ChatGPT-4 to generate articles about the Flooding of the Nile celebrations, employing JSON roles with both JSON and XML templates. The process was near flawless across roles and prompts, which hasn't occurred across multiple AI for quite some time. It makes sense that I would finally have a clean run right before I start experimenting with prompting techniques 😅

### AI Trials: August Pt 2
In August Pt 2, I tested various standalone prompts, from zero-shot to advanced "super prompts." More structured prompts yielded higher-quality content, albeit with varying lengths. Adding templates to few-shot prompts significantly improved results, highlighting the evolution of my prompting strategies away from example-based methods.

### AI Trials: August Pt 3
In August Pt 3, I experimented with Chain of Thought (CoT) prompting using Claude 3.5 Sonnet and ChatGPT-4o to create improved article templates and scoring criteria for Janmashtami articles and future experiments.

---

## September
In September, I focused on refining AI-generated article templates for cultural events, particularly the Autumn Equinox celebrations. The experiments involved multiple iterations of template modification, article generation, and critique using Claude 3.5 Sonnet and ChatGPT-4o. Despite initial promise, the final articles fell short of expectations, highlighting the importance of thorough prompt engineering and testing. The month's trials provided valuable insights into the challenges of AI-assisted content creation and the impact of rushed processes on output quality.

### AI Trials: September Pt 1
In September Pt 1, I revisited the Chain of Thought (CoT) method to create an improved template for articles on global celebrations. This second attempt at CoT prompting was intended to improve upon previous results; however, it resulted in the discovery of a scoring issue that I need to look into.

### AI Trials: September Pt 2
In September Pt 2, I focused on evaluating the effectiveness of two new Chain of Thought (CoT) rubrics against my existing system. I generated articles using zero-shot, one-shot, and few-shot prompting techniques, revealing distinct scoring patterns for each AI model and rubric combination. The new rubrics showed promise in capturing nuanced differences in AI performance, providing insights for future evaluation strategies.

### AI Trials: September Pt 3
In September Pt 3, I challenged AI authors with diverse subjects and input types, testing their ability to adapt existing templates for multi-day events without explicit instructions. I then conducted trials using various markup languages to assess their impact on AI-generated content quality. Employing o1-mini for analysis, I uncovered trends suggesting I may have prematurely settled on JSON as the optimal format for templates.

### AI Trials: September Pt 4
In September Pt 4, I focused on refining AI-generated templates for Autumn Equinox celebrations using Claude 3.5 Sonnet and ChatGPT-4o. Despite multiple iterations, the final articles fell short of expectations. This experiment highlighted the importance of quality prompts and thorough testing in AI-assisted content creation. Rushed processes led to subpar results, providing valuable lessons for future AI experiments.

## October
In October, I refined article templates and tested tone variations across AI models. I analyzed 16 articles with different tones, created 14 pieces on Halloween's history, and found professional tones produced the best content. I also grappled with creating universal templates that work across AI models.

### AI Trials: October Pt 1
October Pt 1 focuses on refining my article templates using three AI models. The experiment involved iterative template modifications, guideline merging, and AI critiques. It raises questions about the challenges in balancing detailed guidance with creative flexibility, revealed differences in AI approaches, and optimizing instructions.

### AI Trials: October Pt 2
October Pt 2 evaluates tone variations and rubric refinement using three AI models. The experiment involved testing 16 article variations with different tones, merging evaluation criteria, and analyzing AI-identified trends. It reveals the effectiveness of professional and neutral tones, highlights the challenges of creating universal templates across AI models, and sets the foundation for future tone experiments.

### AI Trials: October Pt 3
October Part 3 explores the use of AI models to write articles from Halloween's historical perspectives, focusing on the evolution from ancient Celtic traditions to modern celebrations. It outlines the creation and analysis of 14 articles, primarily for entertainment rather than experimental purposes.

---

## November
In November, I explored how different prompt structures affect AI content generation. Starting with basic prompts and progressing to more sophisticated approaches, I tested how varying levels of complexity impacted article quality. The experiments demonstrated the value of structured prompts while revealing scoring inconsistencies between AI models. This led to insights about prompt design and the importance of balancing complexity with practical effectiveness.

### AI Trials: November Pt 1
In November Pt 1, I examined how the complexity of prompts – ranging from simple requests to detailed templates – impacts the quality of AI-generated content. The evaluation scores suggested that the rubric and template structure might be affecting the results in unexpected ways, though both AI models ultimately agreed on the general root cause.

### AI Trials: November Pt 2
In November Pt 2, I explored how different levels of role definition influence the quality of content produced by Claude and GPT-4o. By comparing basic prompts, self-defined roles, and fully structured roles, the study demonstrated that a more structured approach consistently led to superior content quality.

### AI Trials: November Pt 3
In November Pt 3, I investigated the evolution of AI scoring systems and evaluation methods by analyzing articles about Andrés Bonifacio. I found that Claude tended to adjust scores upward consistently, whereas GPT-4o made broader downward revisions with occasional insignificant increases. Notably, one-shot prompt articles performed erratically, underscoring the need for iterative feedback and refinement in evaluation methods.

---

## December
In December, I concluded the year-long experiment by examining how different prompt elements interact. Through systematic testing of combinations and complexity levels, I explored how various prompt components work together to enhance output quality. The experiments revealed patterns in how strategic element combinations can compensate for limitations and demonstrated the value of layered context in prompt design.

### AI Trials: December Pt 1
In December Pt 1, I explored how varying levels of prompt complexity influence AI‐generated content. Using winter solstice celebrations from five cultures as my foundation, I tested how Claude 3.5 and GPT‐4 responded to different levels of instruction detail, ranging from basic guidelines to comprehensive prompts.

### AI Trials: December Pt 2
December Pt 2 explored how different combinations of prompt elements affect AI output quality, examining how roles, templates, tone, and context interact when strategically combined. Building on previous baseline testing, it investigated the relationship between element complexity distribution and content effectiveness.